name: Install and run backstage

on:
  workflow_dispatch:
  push:
    branches:
      - main

env:
  IDPBUILDER_VERSION: v0.4.1

  ## TODO: To be passed to idpbuilder package
  TEKTON_VERSION: v0.60.1

  KUBEVIRT_VERSION: v1.2.1
  KUBEVIRT_CDI_VERSION: v1.59.0

  QUAY_ORG: snowdrop

jobs:
  setup-idp:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'push' && contains( github.event.head_commit.message, 'qshift') }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install idpbuilder
        run: |
          version=${IDPBUILDER_VERSION}
          curl -L -o ./idpbuilder.tar.gz "https://github.com/cnoe-io/idpbuilder/releases/download/${version}/idpbuilder-$(uname | awk '{print tolower($0)}')-$(uname -m | sed 's/x86_64/amd64/').tar.gz"
          tar xzf idpbuilder.tar.gz
          sudo mv ./idpbuilder /usr/local/bin/          

          idpbuilder version

      - name: Install Argocd client
        run: |
          curl -sSL -o argocd-linux-amd64 https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64
          sudo install -m 555 argocd-linux-amd64 /usr/local/bin/argocd
          rm argocd-linux-amd64

      - name: Create an IDP cluster and install the packages
        run: |
          PACKAGES_DIR=.github/resources/idp/packages
          idpbuilder create \
            -p $PACKAGES_DIR/tekton \
            -p $PACKAGES_DIR/backstage

       #- name: Install Kubevirt
       #  run: |
       #    function is_nested_virt_enabled() {
       #      kvm_nested="unknown"
       #      if [ -f "/sys/module/kvm_intel/parameters/nested" ]; then
       #        kvm_nested=$( cat /sys/module/kvm_intel/parameters/nested )
       #      elif [ -f "/sys/module/kvm_amd/parameters/nested" ]; then
       #        kvm_nested=$( cat /sys/module/kvm_amd/parameters/nested )
       #      fi
       #      [ "$kvm_nested" == "1" ] || [ "$kvm_nested" == "Y" ] || [ "$kvm_nested" == "y" ]
       #    }
       #
       #    echo "Deploying KubeVirt"
       #    kubectl apply -f "https://github.com/kubevirt/kubevirt/releases/download/${KUBEVIRT_VERSION}/kubevirt-operator.yaml"
       #    kubectl apply -f "https://github.com/kubevirt/kubevirt/releases/download/${KUBEVIRT_VERSION}/kubevirt-cr.yaml"
       #
       #    echo "Configuring Kubevirt to use emulation if needed"
       #    if ! is_nested_virt_enabled; then
       #      kubectl -n kubevirt patch kubevirt kubevirt --type=merge --patch '{"spec":{"configuration":{"developerConfiguration":{"useEmulation":true}}}}'
       #    fi
       #
       #    echo "Deploying KubeVirt containerized-data-importer"
       #    kubectl apply -f "https://github.com/kubevirt/containerized-data-importer/releases/download/${KUBEVIRT_CDI_VERSION}/cdi-operator.yaml"
       #    kubectl apply -f "https://github.com/kubevirt/containerized-data-importer/releases/download/${KUBEVIRT_CDI_VERSION}/cdi-cr.yaml"
       #
       #    echo "Waiting for KubeVirt to be ready"
       #    kubectl wait --for=condition=Available kubevirt kubevirt --namespace=kubevirt --timeout=5m

       #- name: Give more RBAC to Virt resources and RW for PVC
       #  run: |
       #    echo "Patch the StorageProfile to use the storageclass standard and give ReadWrite access"
       #    kubectl get StorageProfile
       #    kubectl patch --type merge -p '{"spec": {"claimPropertySets": [{"accessModes": ["ReadWriteOnce"], "volumeMode": "Filesystem"}]}}' StorageProfile standard

       #    kubectl create clusterrolebinding pod-kubevirt-viewer --clusterrole=kubevirt.io:view --serviceaccount=default:default
       #    kubectl create clusterrolebinding cdi-kubevirt-viewer --clusterrole=cdi.kubevirt.io:view --serviceaccount=default:default
       #    kubectl create clusterrolebinding quarkus-dev --clusterrole=admin --serviceaccount=default:default

       #- name: Install our Fedora podman image
       #  run: |
       #    kubectl create ns vm-images
       #    kubectl apply -n vm-images -f https://raw.githubusercontent.com/ch007m/test-github-action/main/.github/resources/quay-to-pvc-datavolume.yml
       #    kubectl wait datavolume -n vm-images podman-remote --for condition=Ready=True --timeout=360s

       #- name: Create ssh key, secret and VM
       #  run: |
       #    ssh-keygen -N "" -f id_rsa
       #    kubectl create secret generic quarkus-dev-ssh-key -n default --from-file=key=id_rsa.pub
       #
       #    kubectl apply -f https://raw.githubusercontent.com/ch007m/test-github-action/main/.github/resources/quarkus-dev-vm.yml
       #   kubectl wait --for=condition=Ready vm/quarkus-dev --timeout=360s

      - name: Set idp env variables
        run: |
          GITEA_PASSWORD=$(kubectl get secret/gitea-credential -n gitea -ojson | jq -r '.data.password' | base64 -d)
          GITEA_USERNAME=$(kubectl get secret/gitea-credential -n gitea -ojson | jq -r '.data.username' | base64 -d)
          GITEA_URL=$(kubectl get ingress/my-gitea -n gitea -ojson | jq -r '.spec.rules[0].host')
          echo "GITEA_URL=$GITEA_URL" >> "$GITHUB_ENV"          
          
          # TODO: To be fixed using new idpbuilder release
          # echo "GITEA_PASSWORD=$GITEA_PASSWORD" >> "$GITHUB_ENV"
          echo "GITEA_PASSWORD=ghp_S8GMxiyRdd34ttYU" >> "$GITHUB_ENV"
          
          echo "GITEA_USERNAME=$GITEA_USERNAME" >> "$GITHUB_ENV"
  
          ARGO_PASSWORD=$(kubectl get secret/argocd-initial-admin-secret -n argocd -ojson | jq -r '.data.password' | base64 -d)
          echo "ARGO_PASSWORD=$ARGO_PASSWORD" >> "$GITHUB_ENV"
          echo "ARGO_SERVER=argocd.cnoe.localtest.me:8443" >> "$GITHUB_ENV"
          echo "ARGO_USERNAME=admin" >> "$GITHUB_ENV"
          
          SERVICE_ACCOUNT_TOKEN=$(kubectl get secret backstage-secret -n backstage -o json | jq -r '.data.token' | base64 -d)
          echo "SERVICE_ACCOUNT_TOKEN=$SERVICE_ACCOUNT_TOKEN" >> "$GITHUB_ENV"
          
          BACKSTAGE_AUTH_SECRET=$(node -p 'require("crypto").randomBytes(24).toString("base64")')
          echo "BACKSTAGE_AUTH_SECRET=$BACKSTAGE_AUTH_SECRET" >> "$GITHUB_ENV"
          
          echo "Get node IP and port to access it"
          CLUSTER_IP=$(docker inspect localdev-control-plane | jq -r '.[].NetworkSettings.Ports."6443/tcp"[0].HostIp')
          CLUSTER_PORT=$(docker inspect localdev-control-plane | jq -r '.[].NetworkSettings.Ports."6443/tcp"[0].HostPort')
          
          API_URL="https://$CLUSTER_IP:$CLUSTER_PORT"
          echo "API_URL=$API_URL" >> "$GITHUB_ENV"

      - name: Logon to argocd server
        run: |
          argocd --insecure login $ARGO_SERVER --username $ARGO_USERNAME --password $ARGO_PASSWORD

      - name: Checkout QShift backstage playground
        uses: actions/checkout@v4
        with:
          repository: q-shift/backstage-playground
          path: backstage-playground

      - uses: actions/setup-node@v4
        with:
          node-version: 20.x

      - run: corepack enable

      - name: Install & build QShift
        working-directory: backstage-playground
        run: |
          yarn --immutable
          yarn tsc
          yarn build:all

      - name: Configure app-config.local.yaml file
        env:
          GITHUB_PERSONAL_ACCESS_TOKEN: ${{ secrets.BACKSTAGE_GITHUB_TOKEN }}
        run: |
          cat <<EOF > backstage_env_secret.env
          APP_BASE_URL=http://localhost:3000
          BACKEND_BASE_URL=http://localhost:7007
          
          BACKSTAGE_AUTH_SECRET=$BACKSTAGE_AUTH_SECRET
          
          TEMPLATE_URL=https://github.com/q-shift/backstage-playground/blob/main/locations/root.yaml
          
          ARGOCD_SERVER=$ARGO_SERVER
          ARGOCD_ADMIN_USER=$ARGO_USERNAME
          ARGOCD_ADMIN_PASSWORD=$ARGO_PASSWORD
          
          GITHUB_PERSONAL_ACCESS_TOKEN=$GITHUB_PERSONAL_ACCESS_TOKEN
          
          GITEA_URL=$GITEA_URL
          GITEA_USERNAME=$GITEA_USERNAME
          GITEA_PASSWORD=$GITEA_PASSWORD
          
          KUBERNETES_API_URL=$API_URL
          SERVICE_ACCOUNT_TOKEN=$SERVICE_ACCOUNT_TOKEN
          EOF
          
          export $(grep -v '^#' backstage_env_secret.env | xargs)
          envsubst < .github/resources/app-config.qshift.tmpl > backstage-playground/app-config.local.yaml
          
          cat backstage-playground/app-config.local.yaml

      - name: Start backstage
        # https://github.com/JarvusInnovations/background-action
        uses: JarvusInnovations/background-action@v1
        with:
          run: |
            export NODE_OPTIONS=--no-node-snapshot
            yarn dev
          working-directory: backstage-playground
          tail: true
          log-output: true
          wait-on: http://localhost:7007/settings

      - name: Check backstage resources
        run: |
          get_entities_length() {
              curl -s -H "Authorization: Bearer $BACKSTAGE_AUTH_SECRET" http://localhost:7007/api/catalog/entities?filter=kind=location | jq '. | length'
          }
          
          until [[ $(get_entities_length) -gt 2 ]]; do
             echo "Wait till locations are generated ..."
             length=$(get_entities_length)
             echo "Current length: $length"
             sleep 5
          done
          
          echo "Show the locations ..."
          curl -s "http://localhost:7007/api/catalog/entities?filter=kind=location" \
            -H 'Content-Type: application/json' \
            -H "Authorization: Bearer $BACKSTAGE_AUTH_SECRET" \
            --compressed \
           | jq -r

      - name : Scaffold a project
        run: |
           curl -s 'http://localhost:7007/api/scaffolder/v2/tasks' \
           -X POST \
           -H 'Content-Type: application/json' \
           -H "Authorization: Bearer $BACKSTAGE_AUTH_SECRET" \
           -d @.github/resources/qshift/quarkus-app.json

      - name: Check backstage components
        run: |
          echo "Show the components ..."
          get_entities_length() {
              curl -s -H "Authorization: Bearer $BACKSTAGE_AUTH_SECRET" http://localhost:7007/api/catalog/entities?filter=kind=component | jq '. | length'
          }
          
          until [[ $(get_entities_length) -gt 0 ]]; do
             echo "Wait till component is created ..."
             length=$(get_entities_length)
             echo "Current length: $length"
             sleep 5
          done
          
          curl -s "http://localhost:7007/api/catalog/entities?filter=kind=component" \
            -H 'Content-Type: application/json' \
            -H "Authorization: Bearer $BACKSTAGE_AUTH_SECRET" \
            --compressed \
           | jq -r

      - name: List Argo Application ...
        run: |
          argocd app list