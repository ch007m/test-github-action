name: Run kubevirt on kind

on:
  workflow_dispatch:

env:
  KUBEVIRT_VERSION: v1.0.0
  KUBEVIRT_CDI_VERSION: v1.57.0
  KUBEVIRT_COMMON_INSTANCETYPES_VERSION: v0.3.2
  KUBEVIRT_USE_EMULATION: "true"

jobs:
  kubevirt:
    runs-on: ubuntu-latest
    steps:
       - name: Checkout
         uses: actions/checkout@v3

       - name: Setup kind cluster
         env:
           REGISTRY_NAME: kind-registry
           REGISTRY_PORT: 5000
         run: |
           curl -s -L "https://raw.githubusercontent.com/snowdrop/k8s-infra/main/kind/registry.sh" | bash -s install
           curl -s -L "https://raw.githubusercontent.com/snowdrop/k8s-infra/main/kind/kind.sh" | bash -s install
           
           # Adding registry name to the /etc/hosts file
           echo "127.0.0.1 $REGISTRY_NAME" | sudo tee -a /etc/hosts

           # Exporting the registry location for subsequent jobs
           echo "KIND_REGISTRY=${REGISTRY_NAME}:${REGISTRY_PORT}" >> $GITHUB_ENV

       - name: Setup tools
         env:
           KUBECTL_VERSION: v1.28.1
         run: |
           echo "Installing kubectl"
           curl -LO "https://dl.k8s.io/release/$KUBECTL_VERSION/bin/linux/amd64/kubectl"

       - name: Log versions
         run: |
           echo "OS:"
           cat /etc/os-release
           
           docker -v
           
           echo "kubectl version:"
           kubectl version --client
           
           echo "Kubevirt version: $KUBEVIRT_VERSION"
           
           echo "Virtualization:"
           LC_ALL=C lscpu | grep Virtualization

       # To be validated, but it seems that we don't need it ...
       #- name: Setup qemu
       #  uses: docker/setup-qemu-action@v3

       - name: Deploy kubevirt
         run: |
           function mount_disk() {
             node=$1
             idx=$2
             docker exec $node bash -c "mkdir -p /var/local/kubevirt-storage/local-volume/disk${idx}"
             docker exec $node bash -c "mkdir -p /mnt/local-storage/local/disk${idx}"
             docker exec $node bash -c "mount -o bind /var/local/kubevirt-storage/local-volume/disk${idx} /mnt/local-storage/local/disk${idx}"
           }
           
           function is_nested_virt_enabled() {
             kvm_nested="unknown"
             if [ -f "/sys/module/kvm_intel/parameters/nested" ]; then
               kvm_nested=$( cat /sys/module/kvm_intel/parameters/nested )
             elif [ -f "/sys/module/kvm_amd/parameters/nested" ]; then
               kvm_nested=$( cat /sys/module/kvm_amd/parameters/nested )
             fi
             [ "$kvm_nested" == "1" ] || [ "$kvm_nested" == "Y" ] || [ "$kvm_nested" == "y" ]
           }
           
           NODE_NAME=$(kubectl get nodes -o=jsonpath='{.items[0].metadata.name}')
           echo "Node name is: $NODE_NAME"
           
           #docker exec -t $NODE_NAME bash -c "echo 'fs.inotify.max_user_watches=1048576' >> /etc/sysctl.conf"
           #docker exec -t $NODE_NAME bash -c "echo 'fs.inotify.max_user_instances=512' >> /etc/sysctl.conf"
           #docker exec -i $NODE_NAME bash -c "sysctl -p /etc/sysctl.conf"
  
           echo "Deploying KubeVirt"
           kubectl apply -f "https://github.com/kubevirt/kubevirt/releases/download/${KUBEVIRT_VERSION}/kubevirt-operator.yaml"
           kubectl apply -f "https://github.com/kubevirt/kubevirt/releases/download/${KUBEVIRT_VERSION}/kubevirt-cr.yaml"
         
           echo "Configuring Kubevirt to use emulation"
           if ! is_nested_virt_enabled; then
             kubectl -n kubevirt patch kubevirt kubevirt --type=merge --patch '{"spec":{"configuration":{"developerConfiguration":{"useEmulation":true}}}}'
           fi
           
           echo "Deploying KubeVirt containerized-data-importer"
           kubectl apply -f "https://github.com/kubevirt/containerized-data-importer/releases/download/${KUBEVIRT_CDI_VERSION}/cdi-operator.yaml"
           kubectl apply -f "https://github.com/kubevirt/containerized-data-importer/releases/download/${KUBEVIRT_CDI_VERSION}/cdi-cr.yaml"
           
           echo "Waiting for KubeVirt to be ready"
           kubectl wait --for=condition=Available kubevirt kubevirt --namespace=kubevirt --timeout=5m
           
           # Needed as Storage class is not equal by default to local
           kubectl patch --type merge -p '{"spec": {"claimPropertySets": [{"accessModes": ["ReadWriteOnce"]}]}}' StorageProfile standard
         
           echo "Successfully deployed KubeVirt, CDI:"
           kubectl get pods -n kubevirt
           kubectl get pods -n cdi
                
           # Create local-volume directories, which, on other providers, are pre-provisioned.
           # For more info, check https://github.com/kubevirt/kubevirtci/blob/master/cluster-provision/STORAGE.md
           # for i in {1..10}; do
           #   mount_disk $NODE_NAME $i
           # done
           # docker exec $NODE_NAME bash -c "chmod -R 777 /var/local/kubevirt-storage/local-volume"
           #echo "# Create the local storage class"
           #kubectl apply -f .github/resources/local-volume.yaml

       - name: Creating a VM
         run: |
           echo "## Creating the kubernetes secret storing the public key"
           ssh-keygen -N "" -f id_rsa
           kubectl create secret generic fedora-ssh-key -n default --from-file=key=id_rsa.pub
           
           echo "## Creating a VM"
           kubectl apply -f .github/resources/vm-fedora38.yml
           
           kubectl wait --for=condition=Ready vm/fedora38 --timeout=5m
           
           # Create a k8s service to expose the socat port
           kubectl apply -f .github/resources/service-2376.yml

       - name: Wait till podman replies
         run: |
           VM_IP=$(kubectl get vmi -o jsonpath='{.items[0].status.interfaces[0].ipAddress}')
           echo "VM IP is: $VM_IP"
           
           # Launch the podman client
           kubectl run podname-client --image=quay.io/podman/stable -- "sleep" "1000000" &
          
           # Wait for the pod to be in the Running state
           while true; do
              pod_status=$(kubectl get pod podname-client -ojsonpath='{.status.phase}')
              if [ "$pod_status" == "Running" ]; then
                  break
              fi
              echo "podman client is not yet running ..."
              sleep 5
           done
           echo "Pod podname-client is in the Running state."
           
           echo "Wait for the command within the pod to succeed"
           echo ">>>> Command to be executed to check healthiness of podman & socat"
           echo ">>>> kubectl exec podname-client -- podman \"-r\" \"--url=tcp://podman-remote:2376\" \"version\""
           while true; do
               kubectl exec podname-client -- podman "-r" "--url=tcp://podman-remote:2376" "version"
               if [ $? -eq 0 ]; then
                   echo "Command within the pod succeeded."
                   break
               else
                   echo "Remote podman is not yet ready to reply.."
               fi
               sleep 20
           done
           #kubectl delete pod podname-client
           
       - name: (Only if it failed) Log messages
         if: failure()
         run: |
           echo "########### Virt Handler & controller logs ################"
           kubectl logs -lkubevirt.io=virt-handler -n kubevirt
           kubectl logs -lkubevirt.io=virt-controller -n kubevirt

           echo "########### DataVolume ################"
           kubectl describe datavolume/fedora38
           kubectl get datavolume/fedora38 -oyaml
           
           echo "########### Describe VM ################"
           echo "Describe virtualmachine/fedora38"
           kubectl describe virtualmachine/fedora38
           
           echo "########### VM status ################"
           kubectl get virtualmachine/fedora38 -oyaml
           
           echo "########### VMI status ################"
           kubectl get vmi -A -oyaml
           
           echo "########### VM POD ################"
           kubectl get pod -lvm.kubevirt.io/name=fedora38 -oyaml
           
           echo "########### All PODs ################"
           kubectl get pod -A

           echo "######### Services ################"
           kubectl get svc -A
           
           #echo "######### PVC ################"
           #kubectl get pvc -A
           
           #echo "########### SC ####################"
           #kubectl get sc -A -oyaml
